{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train a neural network, we need a database of identically formatted fire tensors.\n",
    "\n",
    "This notebook scans a fire perimeter for interesting convolutions, 256x256 30m squares where there is a mix of burning and non-burning areas, the fire has not overrun the boundaries, which would cause training errors. The results are then stored in a MongoDB for easy access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pymongo as pm\n",
    "import pyprind\n",
    "import collections\n",
    "import matplotlib as mpl\n",
    "import pickle\n",
    "import datetime as dt\n",
    "import geopandas as gpd\n",
    "\n",
    "cmap = mpl.colors.ListedColormap(['black', 'red', 'yellow', 'blue', 'green'])\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FBFM40 is the Scott and Burgan Fire Behavior Fuel Model, which describes flammable materials on 40 landscape types. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "FBFM40 = pd.read_csv('FBFM40convert.csv', header=0, index_col=0)\n",
    "\n",
    "fbfm401hr = dict()\n",
    "fbfm4010hr = dict()\n",
    "fbfm40100hr = dict()\n",
    "fbfm40live = dict()\n",
    "fbfm40woody = dict()\n",
    "fbfm40dead = dict ()\n",
    "for row in FBFM40.itertuples():\n",
    "    fbfm401hr[row[0]]   = row[2]\n",
    "    fbfm4010hr[row[0]]  = row[3]\n",
    "    fbfm40100hr[row[0]] = row[4]\n",
    "    fbfm40live[row[0]]  = row[5]\n",
    "    fbfm40woody[row[0]] = row[6]\n",
    "    fbfm40dead[row[0]]  = row[7]/100\n",
    "\n",
    "fbfm = np.zeros([205,6])\n",
    "\n",
    "for item in fbfm401hr:\n",
    "    fbfm[item,0] = fbfm401hr[item]\n",
    "    fbfm[item,1] = fbfm4010hr[item]\n",
    "    fbfm[item,2] = fbfm40100hr[item]\n",
    "    fbfm[item,3] = fbfm40live[item]\n",
    "    fbfm[item,4] = fbfm40woody[item]\n",
    "    fbfm[item,5] = fbfm40dead[item]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolute(raster, coords):\n",
    "    \"\"\"\n",
    "    Takes in a raster and a coordinate list of [left, right, top, bottom]\n",
    "    Returns convolution\"\"\"\n",
    "    return raster[coords[2]:coords[3],coords[0]:coords[1]]\n",
    "\n",
    "def convolute3d(raster, coords):\n",
    "    \"\"\"\n",
    "    Takes in a raster and a coordinate list of [left, right, top, bottom, t0, t1]\n",
    "    Returns convolution\"\"\"\n",
    "    return raster[coords[4]:coords[5],coords[2]:coords[3],coords[0]:coords[1]]\n",
    "\n",
    "def coord_gen(shape, conv_size, stride):\n",
    "    \"\"\"\n",
    "    Takes in a np.shape, and desired convolution size and stride.\n",
    "    Returns a valid list of coordinates for that shape\n",
    "    \"\"\"\n",
    "    coords = []\n",
    "    xs = np.arange(0, shape[1]-conv_size, stride)\n",
    "    ys = np.arange(0, shape[0]-conv_size, stride)\n",
    "    for y in ys:\n",
    "        for x in xs:\n",
    "            new_coord = [x, x+conv_size, y, y+conv_size]\n",
    "            coords.append(new_coord)\n",
    "    return(coords)\n",
    "\n",
    "def perimeter_finder(ar, br, conv_size, stride):\n",
    "    \"\"\"\n",
    "    ar and br are two fire perimeters from the same fire separated by a reasonable interval\n",
    "    conv_size and stride and the convolution size and stride\n",
    "    \"\"\"\n",
    "    \n",
    "    interesting_coords = []\n",
    "\n",
    "    for coord in coord_gen(ar.shape, conv_size, stride):\n",
    "        ac = convolute(ar, coord)\n",
    "        bc = convolute(br, coord)\n",
    "        max_area = ac.shape[0]*ac.shape[1]\n",
    "        if 0 < np.sum(ac) and np.sum(ac) < max_area:\n",
    "            interesting_coords.append(coord)\n",
    "    return interesting_coords\n",
    "\n",
    "def azimuthx(a):\n",
    "    return np.cos(np.radians(a))\n",
    "\n",
    "def azimuthy(a):\n",
    "    return np.sin(np.radians(a))\n",
    "\n",
    "def bytes_to_raster(buf, shape):\n",
    "    br = np.frombuffer(buf, dtype=np.float)\n",
    "    r = br.reshape(shape)\n",
    "    return r\n",
    "\n",
    "def db_update(ic):\n",
    "    c_perim1 = convolute(perim1['raster'], ic)\n",
    "    c_perim0 = convolute(perim0['raster'], ic)\n",
    "    c_dem = convolute(topo['us_dem'], ic)\n",
    "    c_slp = convolute(topo['us_slp'], ic)  \n",
    "    c_asp = convolute(topo['us_asp'], ic)  \n",
    "    c_fbfm40 = convolute(topo['us_130fbfm40'], ic)  \n",
    "\n",
    "    c=np.zeros([12, 256, 256])\n",
    "\n",
    "    c[0,:,:] = c_perim1\n",
    "    c[1,:,:] = c_perim0\n",
    "    c[2,:,:] = c_dem-np.mean(c_dem)\n",
    "    c[3,:,:] = azimuthx(c_asp)\n",
    "    c[4,:,:] = azimuthy(c_asp)\n",
    "    c[5,:,:] = c_slp\n",
    "    for i in range(256):\n",
    "        for j in range(256):\n",
    "            c[6:12,i,j]= fbfm[c_fbfm40[i,j]]\n",
    "\n",
    "\n",
    "    topo_shape = perim1['raster'].shape\n",
    "\n",
    "    enddate = dt.datetime.strptime(atmo['enddate'], '%Y-%m-%d')\n",
    "    startdate = dt.datetime.strptime(atmo['startdate'], '%Y-%m-%d')\n",
    "\n",
    "    zero = startdate + dt.timedelta(hours=-1000)\n",
    "    now = dt.datetime.strptime(perim0['date'], '%Y-%m-%d')\n",
    "    predict = dt.datetime.strptime(perim1['date'], '%Y-%m-%d')\n",
    "\n",
    "    t1 = enddate-predict\n",
    "\n",
    "    t1_index = t1.days*24\n",
    "\n",
    "    t0 = enddate-now\n",
    "\n",
    "    t0_index = t0.days*24\n",
    "\n",
    "    atmo_shape = atmo['windspeed'].shape[1:]\n",
    "    conversion_factor = np.mean(topo_shape[0]/atmo_shape[0]+topo_shape[1]/atmo_shape[1])\n",
    "    atmo_coords = np.round(ic/conversion_factor, 0)\n",
    "    atmo_coords = [int(x) for x in atmo_coords]\n",
    "    atmo_coords = [-t0_index, -t1_index] + atmo_coords\n",
    "    ac =atmo_coords\n",
    "    if ac[1] == 0:\n",
    "        ac[1] = -1\n",
    "        ac[0] = ac[0] -1\n",
    "\n",
    "    c_winddir   = atmo['winddirection'][ac[0]:ac[1], ac[2]:ac[3], ac[4]:ac[5]]\n",
    "    c_windspeed = atmo['windspeed'][ac[0]:ac[1], ac[2]:ac[3], ac[4]:ac[5]]\n",
    "    c_precip    = atmo['precipitation'][ac[0]:ac[1], ac[2]:ac[3], ac[4]:ac[5]]\n",
    "    c_humid     = atmo['humidity'][ac[0]:ac[1], ac[2]:ac[3], ac[4]:ac[5]]\n",
    "    c_temp      = atmo['temperature'][ac[0]:ac[1], ac[2]:ac[3], ac[4]:ac[5]]\n",
    "\n",
    "    a = np.zeros([6, t0_index-t1_index, c_winddir.shape[1], c_winddir.shape[2]])\n",
    "\n",
    "    a[0, :, :, :] = azimuthx(c_winddir)\n",
    "    a[1, :, :, :] = azimuthy(c_winddir)\n",
    "    a[2, :, :, :] = c_windspeed\n",
    "    a[3  :, :, :] = c_precip\n",
    "    a[4, :, :, :] = c_humid\n",
    "    a[5, :, :, :] = c_temp -273\n",
    "\n",
    "    date = now.strftime('%Y-%d-%m')\n",
    "\n",
    "    data = {\n",
    "    'fire_id':fire_id,\n",
    "    'date': date,\n",
    "    't_shape' : c.shape,\n",
    "    'a_shape' : a.shape,\n",
    "    'topo' : c.tobytes(),\n",
    "    'atmo' : a.tobytes()\n",
    "    }\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "atmo_files=os.listdir('wind')\n",
    "topo_files=os.listdir('topo')\n",
    "perim_files = os.listdir('perims/clean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139\n",
      "137\n"
     ]
    }
   ],
   "source": [
    "#these two fires cause problems, due to their enormous size.\n",
    "\n",
    "fire_ids =  [x.split(' ')[0] for x in atmo_files]\n",
    "print(len(fire_ids))\n",
    "fire_ids.remove('ID-SCF-G4A0')\n",
    "fire_ids.remove('WA-OWF-G70S')\n",
    "print(len(fire_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [#############################################################################   ] 100% | ETA: 00:00:09\n",
      "Total time elapsed: 00:04:21\n"
     ]
    }
   ],
   "source": [
    "# Counting the number of interesting convolutions. Can be skipped.\n",
    "\n",
    "# num_conv = 0\n",
    "\n",
    "# progbar = pyprind.ProgBar(len(fire_ids), width=80, update_interval=5)\n",
    "\n",
    "# for fire_id in fire_ids:\n",
    "\n",
    "#     layers = ['us_slp', 'us_dem', 'us_asp', 'us_130fbfm40']\n",
    "\n",
    "#     for layer in layers:\n",
    "#         topo[layer] = topo[layer].T\n",
    "\n",
    "#     perims = [x for x in perim_files if fire_id in x]\n",
    "#     perims.sort()\n",
    "\n",
    "#     for s in range(len(perims)-1):\n",
    "#         op = open('perims/clean/'+perims[s+1], 'rb')\n",
    "#         perim0 = pickle.load(op)\n",
    "#         op.close()\n",
    "\n",
    "#         op = open('perims/clean/'+perims[s], 'rb')\n",
    "#         perim1 = pickle.load(op)\n",
    "#         op.close()\n",
    "\n",
    "#         perim0['raster'] = perim0['raster'].astype(int)\n",
    "#         perim1['raster'] = perim1['raster'].astype(int)\n",
    "\n",
    "#         ics = perimeter_finder(perim0['raster'], perim1['raster'], 256, 32)\n",
    "#         num_conv +=len(ics)\n",
    "#     progbar.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "642893"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#if you want to run this quickly\n",
    "num_conv = 642893\n",
    "\n",
    "num_conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = pm.MongoClient()\n",
    "local = client.firemind\n",
    "\n",
    "firemind.drop_collection('convolutions')\n",
    "firemind.create_collection('convolutions')\n",
    "\n",
    "convolutions = firemind.get_collection('convolutions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [                                                                                ] 100% | ETA: 22:24:36"
     ]
    }
   ],
   "source": [
    "errors = []\n",
    "\n",
    "progbar = pyprind.ProgBar(num_conv, width=80, update_interval=5)\n",
    "\n",
    "for fire_id in [fire_ids[0]]:\n",
    "\n",
    "    op = open('wind/'+fire_id+' wind.pkl', 'rb')\n",
    "    atmo = pickle.load(op)\n",
    "    op.close()\n",
    "\n",
    "    op = open('topo/'+fire_id+' topo.pkl', 'rb')\n",
    "    topo = pickle.load(op)\n",
    "    op.close()\n",
    "\n",
    "    layers = ['us_slp', 'us_dem', 'us_asp', 'us_130fbfm40']\n",
    "\n",
    "    for layer in layers:\n",
    "        topo[layer] = topo[layer].T\n",
    "\n",
    "    perims = [x for x in perim_files if fire_id in x]\n",
    "    perims.sort()\n",
    "\n",
    "    for s in range(len(perims)-1):\n",
    "        op = open('perims/clean/'+perims[s], 'rb')\n",
    "        perim0 = pickle.load(op)\n",
    "        op.close()\n",
    "\n",
    "        op = open('perims/clean/'+perims[s+1], 'rb')\n",
    "        perim1 = pickle.load(op)\n",
    "        op.close()\n",
    "\n",
    "        perim0['raster'] = perim0['raster'].astype(int)\n",
    "        perim1['raster'] = perim1['raster'].astype(int)\n",
    "        #print(perim1['date'], perim0['date'])\n",
    "\n",
    "        ics = perimeter_finder(perim0['raster'], perim1['raster'], 256, 32)\n",
    "\n",
    "        for ic in ics:\n",
    "            c_perim1 = convolute(perim1['raster'], ic)\n",
    "            c_perim0 = convolute(perim0['raster'], ic)\n",
    "            c_dem = convolute(topo['us_dem'], ic)\n",
    "            c_slp = convolute(topo['us_slp'], ic)  \n",
    "            c_asp = convolute(topo['us_asp'], ic)  \n",
    "            c_fbfm40 = convolute(topo['us_130fbfm40'], ic)  \n",
    "\n",
    "            c=np.zeros([12, 256, 256])\n",
    "\n",
    "            c[0,:,:] = c_perim1\n",
    "            c[1,:,:] = c_perim0\n",
    "            c[2,:,:] = c_dem-np.mean(c_dem)\n",
    "            c[3,:,:] = azimuthx(c_asp)\n",
    "            c[4,:,:] = azimuthy(c_asp)\n",
    "            c[5,:,:] = c_slp\n",
    "            for i in range(256):\n",
    "                for j in range(256):\n",
    "                    c[6:12,i,j]= fbfm[c_fbfm40[i,j]]\n",
    "\n",
    "\n",
    "            topo_shape = perim1['raster'].shape\n",
    "\n",
    "            enddate = dt.datetime.strptime(atmo['enddate'], '%Y-%m-%d')\n",
    "            startdate = dt.datetime.strptime(atmo['startdate'], '%Y-%m-%d')\n",
    "\n",
    "            zero = startdate + dt.timedelta(hours=-1000)\n",
    "            \n",
    "            now = dt.datetime.strptime(perim0['date'], '%Y-%m-%d')\n",
    "            predict = dt.datetime.strptime(perim1['date'], '%Y-%m-%d')\n",
    "\n",
    "            t0 = int((predict-startdate).total_seconds()/3600+900)\n",
    "\n",
    "            t1_index = int((now-startdate).total_seconds()/3600+1000)\n",
    "\n",
    "            atmo_shape = atmo['windspeed'].shape[1:]\n",
    "            conversion_factor = np.mean(topo_shape[0]/atmo_shape[0]+topo_shape[1]/atmo_shape[1])\n",
    "            atmo_coords = np.round(ic/conversion_factor, 0)\n",
    "            atmo_coords = [int(x) for x in atmo_coords]\n",
    "            atmo_coords = [t0_index, t1_index] + atmo_coords\n",
    "            ac =atmo_coords\n",
    "\n",
    "            c_winddir   = atmo['winddirection'][ac[0]:ac[1], ac[2]:ac[3], ac[4]:ac[5]]\n",
    "            c_windspeed = atmo['windspeed'][ac[0]:ac[1], ac[2]:ac[3], ac[4]:ac[5]]\n",
    "            c_precip    = atmo['precipitation'][ac[0]:ac[1], ac[2]:ac[3], ac[4]:ac[5]]\n",
    "            c_humid     = atmo['humidity'][ac[0]:ac[1], ac[2]:ac[3], ac[4]:ac[5]]\n",
    "            c_temp      = atmo['temperature'][ac[0]:ac[1], ac[2]:ac[3], ac[4]:ac[5]]\n",
    "\n",
    "            a = np.zeros([6, t1_index-t0_index, c_winddir.shape[1], c_winddir.shape[2]])\n",
    "\n",
    "            a[0, :, :, :] = azimuthx(c_winddir)\n",
    "            a[1, :, :, :] = azimuthy(c_winddir)\n",
    "            a[2, :, :, :] = c_windspeed\n",
    "            a[3  :, :, :] = c_precip\n",
    "            a[4, :, :, :] = c_humid\n",
    "            a[5, :, :, :] = c_temp -273\n",
    "\n",
    "            date = now.strftime('%Y-%d-%m')\n",
    "\n",
    "            data = {\n",
    "            'fire_id':fire_id,\n",
    "            'date': date,\n",
    "            't_shape' : c.shape,\n",
    "            'a_shape' : a.shape,\n",
    "            'topo' : c.tobytes(),\n",
    "            'atmo' : a.tobytes()\n",
    "            }\n",
    "            convolutions.insert_one(data)\n",
    "            progbar.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.6/site-packages/ipykernel_launcher.py:1: DeprecationWarning: count is deprecated. Use estimated_document_count or count_documents instead. Please note that $where must be replaced by $expr, $near must be replaced by $geoWithin with $center, and $nearSphere must be replaced by $geoWithin with $centerSphere\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1030"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convolutions.estimated_document_count()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
